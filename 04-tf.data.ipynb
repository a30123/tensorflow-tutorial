{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tf.data\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjw/anaconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n",
      "()\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(3,)\n",
      "[0.83832157 0.8037684  0.8136611 ]\n",
      "[0.15484905 0.17452276 0.5419953 ]\n",
      "[0.509969   0.6895293  0.22684693]\n",
      "[0.48337054 0.3877033  0.37009656]\n",
      "[0.0836699  0.43567216 0.47110868]\n",
      "[0.91641974 0.9297267  0.9373778 ]\n",
      "[0.96969664 0.6759572  0.89000905]\n",
      "[0.9392942 0.9988909 0.3330177]\n",
      "[0.7647575  0.02365232 0.27215362]\n",
      "[0.21679962 0.77614367 0.6169944 ]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([10, 3]))\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(10):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q\n",
    "計算 $1+2+...+10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_initializable_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "min_value = tf.placeholder(tf.int64, shape=[])\n",
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(min_value, max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize an iterator over a dataset with 10 elements.\n",
    "    sess.run(iterator.initializer, feed_dict={min_value: 0, max_value: 5})\n",
    "    for i in range(5):\n",
    "        print(sess.run(next_element))\n",
    "\n",
    "    # Initialize the same iterator over a dataset with 10 elements.\n",
    "    sess.run(iterator.initializer, feed_dict={min_value: 100, max_value: 105})\n",
    "    for i in range(5):\n",
    "        value = sess.run(next_element)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinitializable (one interator with different datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train 0 9\n",
      "train 1 8\n",
      "train 2 8\n",
      "train 3 1\n",
      "train 4 7\n",
      "train 5 8\n",
      "train 6 8\n",
      "train 7 16\n",
      "train 8 13\n",
      "train 9 7\n",
      "validation 0 0\n",
      "validation 1 1\n",
      "validation 2 2\n",
      "validation 3 3\n",
      "validation 4 4\n",
      "epoch 1\n",
      "train 0 -7\n",
      "train 1 -5\n",
      "train 2 4\n",
      "train 3 12\n",
      "train 4 1\n",
      "train 5 13\n",
      "train 6 -2\n",
      "train 7 4\n",
      "train 8 14\n",
      "train 9 15\n",
      "validation 0 0\n",
      "validation 1 1\n",
      "validation 2 2\n",
      "validation 3 3\n",
      "validation 4 4\n",
      "epoch 2\n",
      "train 0 -9\n",
      "train 1 -1\n",
      "train 2 -1\n",
      "train 3 6\n",
      "train 4 3\n",
      "train 5 -3\n",
      "train 6 5\n",
      "train 7 15\n",
      "train 8 12\n",
      "train 9 16\n",
      "validation 0 0\n",
      "validation 1 1\n",
      "validation 2 2\n",
      "validation 3 3\n",
      "validation 4 4\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(10).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# two dataset are compatible\n",
    "assert training_dataset.output_types == validation_dataset.output_types\n",
    "assert training_dataset.output_shapes == validation_dataset.output_shapes\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "def loop_through_dataset(ds_name, n):\n",
    "        for _ in range(n):\n",
    "            print(ds_name, _, sess.run(next_element))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for epoch in range(3):    \n",
    "        print(\"epoch\", epoch)\n",
    "        # training\n",
    "        sess.run(training_init_op)\n",
    "        loop_through_dataset(\"train\", 10)\n",
    "\n",
    "        # Validation\n",
    "        sess.run(validation_init_op)\n",
    "        loop_through_dataset(\"validation\", 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import pickle\n",
    "with lzma.open(\"mnist.pkl.xz\", 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_set\n",
    "validation_X, validation_y = validation_set\n",
    "test_X, test_y = test_set\n",
    "train_Y = np.eye(10)[train_y]\n",
    "test_Y = np.eye(10)[test_y]\n",
    "validation_Y = np.eye(10)[validation_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=560x28 at 0x181C80F898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))\n",
    "# 訓練資料， X 的前 20 筆\n",
    "showX(train_X[:20])\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始 Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tfdot import tfdot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 gfile 來讀檔\n",
    "from tensorflow.python.platform import gfile\n",
    "# 讀入 graph_def\n",
    "with gfile.FastGFile(\"mnist_simple.pb\",'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    x = f.read()\n",
    "    #print(x)\n",
    "    graph_def.ParseFromString(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用之前存下來的模型\n",
    "X, Y_, prediction, accuracy, train_step, keep_prob, init_op= tf.import_graph_def(graph_def, name=\"\", \n",
    "        return_elements=[\"X:0\", \"Y_:0\", \"prediction:0\", \n",
    "                         \"accuracy:0\", \"Adam\", 'dropout/keep_prob:0', \"init\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init_op.run()\n",
    "tf.summary.scalar(accuracy.op.name, accuracy)\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(\"log1\", graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    rnd_idx = np.random.choice(train_X.shape[0], 50, replace=False)\n",
    "    if i%250 == 0:       \n",
    "        summary_str, validation_accuracy = sess.run([summary_op, accuracy],\n",
    "                        {X: validation_X[:1000], \n",
    "                                       Y_: validation_Y[:1000], \n",
    "                                       keep_prob: 1.0 })\n",
    "        summary_writer.add_summary(summary_str, i)\n",
    "        print(\"step %d, validation accuracy: %g\"%(i, validation_accuracy))\n",
    "    train_step.run({X: train_X[rnd_idx], Y_: train_Y[rnd_idx], keep_prob: 0.5 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run `tensorboard --logdir=log1` in terminal and open http://localhost:6006\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=log1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同時紀錄三種準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init_op.run()\n",
    "acc_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "training_summary_writer = tf.summary.FileWriter(\"log2/training\", graph=sess.graph)\n",
    "validation_summary_writer = tf.summary.FileWriter(\"log2/validation\", graph=sess.graph)\n",
    "testing_summary_writer = tf.summary.FileWriter(\"log2/testing\", graph=sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    rnd_idx = np.random.choice(train_X.shape[0], 50, replace=False)\n",
    "    if i%50 == 0:       \n",
    "        summary_str, training_acc = sess.run([acc_summary, accuracy],\n",
    "                        {X: train_X[:1000], Y_: train_Y[:1000], keep_prob: 1.0 })\n",
    "        training_summary_writer.add_summary(summary_str, i)\n",
    "        summary_str, validation_acc = sess.run([acc_summary, accuracy],\n",
    "                        {X: validation_X[:1000], Y_: validation_Y[:1000], keep_prob: 1.0 })\n",
    "        validation_summary_writer.add_summary(summary_str, i)\n",
    "        summary_str, testing_acc = sess.run([acc_summary, accuracy],\n",
    "                        {X: test_X[:1000], Y_: test_Y[:1000], keep_prob: 1.0 })\n",
    "        testing_summary_writer.add_summary(summary_str, i)\n",
    "        if i%250==0:\n",
    "            print(\"step %d, train: %g, validation: %g, test: %g\"%(i, training_acc, \n",
    "                                                              validation_acc, testing_acc))\n",
    "    train_step.run({X: train_X[rnd_idx], Y_: train_Y[rnd_idx], keep_prob: 0.5 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_summary_writer.close()\n",
    "validation_summary_writer.close()\n",
    "training_summary_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=log2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
